---
title: "Part 1.1 Data Preparation and Exploration (Computer Practical)"
author: 
  - name: "Aulia Kharis"
    affiliation: "Smart Data Analysis & Statistics"
  - name: "Thomas Debray"
    affiliation: "Smart Data Analysis & Statistics"
format: 
  html :
    toc: true 
    toc-depth: 3    
    toc-location: right
    number-sections: false 
editor: visual
---

# Summary

Clinical prediction models are statistical or machine learning tools designed to estimate the likelihood of future health outcomes for individuals based on a set of baseline characteristics, such as demographic information, clinical measurements, or laboratory results. 

Ideally, these models should be developed using high-quality individual participant data collected from prospective cohort studies that are specifically designed for prediction purposes. 

The use of prospective cohorts allows researchers to accurately assess the relationship between predictors and future health events, which is essential for building reliable and generalizable models.

In this vignette, you will engage in hands-on tasks designed to deepen your understanding of how clinical prediction modeling works in practice. You will begin with **Part 1: Data Preparation and Exploration**, which is a critical phase in the modeling process. This stage involves examining the dataset, understanding the nature of the variables, checking distributions, and visualize some of the variables.

# 1. Preparation

Please complete these following setups on your computer :

## 1.1 Install R and Rstudio

-   Download and install R from: <https://cran.r-project.org/>
-   Download and install RStudio (Desktop version) from: <https://posit.co/download/rstudio-desktop/>

## 1.2 Install Required R Packages

Open RStudio and run the following code to install the necessary packages (skip any that are already installed):

```{r}
#| eval: false
#| include: true
install.packages(c('ggplot2','dplyr','correlation'))
```

## 1.3 Download Dataset

There is already pre-built dataset that contain 200 patients, saved in rds files. Download 'dataset.rds' file and ensure that this file saved in your current working directory.

<https://github.com/smartdata-analysis-and-statistics/precision-medicine-practicals>

# 2. Load Data

To start the hands-on practical, open R-Studio and load the required packages.

```{r}
#| eval: false
#| include: true
library(ggplot2)
library(dplyr)
library(corrplot)
library(gridExtra)
```

After the package has been successfully loaded, then load the required dataset that has been downloaded.

```{r}
#| eval: false
#| include: true
df = readRDS('dataset.rds')
```

# 3. Descriptive Statistics and Visualizations

Before we build any predictive model, it is crucial to thoroughly explore and understand the dataset. This section will guide you through essential descriptive statistics and visualizations to better comprehend the structure, distribution, and relationships within the data.

## 3.1 Descriptive Summary

Begin by inspecting the structure of the dataset and summarizing its variables using the `summary()` function.

**Tasks:**

-   View basic descriptive statistics of each variable.
-   Check the data types (numeric, factor, character, etc.).

```{r}
#| eval: false
#| include: true
summary(df)
```

**Questions for Discussion:**

-   How many variables are included in the dataset?
-   Are all variables of the same type, or do they differ?
-   Are there any variables that appear irrelevant or redundant?

## 3.2 Missing Values

Check for any missing values in the dataset, which could impact model performance if not handled properly. Use `is.na()` and `colSums()` or `summary()` to identify missing data.

```{r}
#| eval: false
#| include: true
colSums(is.na(df))
```

**Questions for Discussion:**

-   Are there any missing values in the dataset?
-   Which variables have missing values?
-   What proportion of data is missing?
-   How might we handle the missing data (e.g., imputation, removal)?

## 3.3 Distribution of Numeric Variables

Visualize the distribution of numeric variables using histograms to understand their shapes, spread, and central tendencies.

```{r}
#| eval: false
#| include: true
# Histograms for continuous variables
p1 <- ggplot(df, aes(x = x1)) + 
  geom_histogram(bins = 20, fill = "skyblue", alpha = 0.7, color = "black") +
  labs(title = "Distribution of X1", x = "X1", y = "Frequency") + theme_minimal()

p2 <- ggplot(df, aes(x = x2)) + 
  geom_histogram(bins = 20, fill = "lightgreen", alpha = 0.7, color = "black") +
  labs(title = "Distribution of X2", x = "X2", y = "Frequency") + theme_minimal()

# Combine plots
grid.arrange(p1, p2, ncol = 2, top = "Distribution of Continuous Variables")
```

**Questions for Discussion:**

-   Do the numeric variables follow a normal distribution?
-   Are there noticeable differences in distribution across numeric variables?
-   Are there any skewed distributions or outliers?
-   Should any transformations (e.g., log, square root) be applied before modeling?

## 3.4 Distribution of Categorical Variables

Explore the frequency distribution of categorical variables using bar plots.

```{r}
#| eval: false
#| include: true
# 4.2 Bar plots for categorical variables
p5 <- ggplot(df, aes(x = x3)) + 
  geom_bar(fill = "steelblue", alpha = 0.7) +
  labs(title = "Distribution of X3", x = "X3", y = "Count") + theme_minimal()

p6 <- ggplot(df, aes(x = x4)) + 
  geom_bar(fill = "darkgreen", alpha = 0.7) +
  labs(title = "Distribution of X4", x = "X4", y = "Count") + theme_minimal()

p7 <- ggplot(df, aes(x = x5)) + 
  geom_bar(fill = "purple", alpha = 0.7) +
  labs(title = "Distribution of X5", x = "X5", y = "Count") + theme_minimal()

p8 <- ggplot(df, aes(x = y)) + 
  geom_bar(fill = "red", alpha = 0.7) +
  labs(title = "Distribution of Outcome Y", x = "Y", y = "Count") + theme_minimal()

grid.arrange(p5, p6, p7, p8, ncol = 2, top = "Distribution of Categorical Variables")
```

**Questions for Discussion:**

-   What is the distribution of categories within each variable?
-   Are some categories underrepresented or overrepresented?
-   Could any variables benefit from combining sparse levels?
-   Do any imbalances suggest potential bias or modeling challenges?

## 3.5 Correlation

Analyze pairwise correlations to understand the linear relationships between variables. Use correlation coefficients (Pearson, Spearman, or Cramér's V for categorical) and visualize them.

```{r}
#| eval: false
#| include: true
cor_result = correlation(df)
cor_result
```

**Questions for Discussion:**

-   At a 90% confidence level, which variable pairs have statistically significant correlations?
-   Which variables are most strongly correlated with the response variable (`y`)?
-   Are there any signs of multicollinearity that might affect model stability?

The correlation plot will help to visualize the correlation of each variables.

```{r}
#| eval: false
#| include: true
plot(cor_result)
```

## 3.6 Relationship between Predictors and Response Variables

Explore how the predictor variables relate to the response variable. This can reveal early signs of predictive power and potential modeling strategies.

### 3.6.1 Numerical Predictors vs Response Variables

Use boxplots to assess the relationship between continuous predictors and the response variable.

```{r}
#| eval: false
#| include: true
p10 <- ggplot(df, aes(x = y, y = x1, fill = y)) + 
  geom_boxplot(alpha = 0.7) +
  labs(title = "X1 by Outcome Y", x = "Y", y = "X1") + theme_minimal() +
  theme(legend.position = "none")

p11 <- ggplot(df, aes(x = y, y = x2, fill = y)) + 
  geom_boxplot(alpha = 0.7) +
  labs(title = "X2 by Outcome Y", x = "Y", y = "X2") + theme_minimal()

grid.arrange(p10, p11, ncol = 2, top = "Continuous Predictors by Outcome")
```

**Questions for Discussion:**

-   Is there a visible trend or pattern between numeric predictors and the response?

### 3.6.2 Categorical Predictors vs Response Variables

Use grouped bar plots to explore how categorical predictors influence the response.

```{r}
#| eval: false
#| include: true
p12 <- ggplot(df, aes_string(x = x3, fill = "factor(y)")) +
  geom_bar(position = "fill") +  # stacked proportion bars
  ylab("Proportion") +
  labs(fill = "y", title = paste("X3 by Outcome Y")) + theme_minimal()

p13 <- ggplot(df, aes_string(x = x4, fill = "factor(y)")) +
  geom_bar(position = "fill") +  # stacked proportion bars
  ylab("Proportion") +
  labs(fill = "y", title = paste("X4 by Outcome Y")) + theme_minimal()

p14 <- ggplot(df, aes_string(x = x5, fill = "factor(y)")) +
  geom_bar(position = "fill") +  # stacked proportion bars
  ylab("Proportion") +
  labs(fill = "y", title = paste("X5 by Outcome Y")) + theme_minimal()


grid.arrange(p12, p13, p14, ncol = 2, top = "Categorical Predictors by Outcome")

```

**Questions for Discussion:**

-   Are there noticeable differences in the response variable across categories?
-   Do any levels dominate the distribution?
